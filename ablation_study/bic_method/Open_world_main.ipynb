{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Open_world_main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRMZaj4O3vhq1zkKtR0zBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "253cb41ffedc4cc0a2440b87972ab607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e567fb7101e349c6ac09f0e931e071cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8b8bef9195e44bc87d18d44f3b59d6b",
              "IPY_MODEL_e6139fc3bba94c58b4f8daeda560c0f3"
            ]
          }
        },
        "e567fb7101e349c6ac09f0e931e071cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8b8bef9195e44bc87d18d44f3b59d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f65e2a5f261940838cf1bb34926b0948",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_761c699d8a614d0babd708f57b227dcb"
          }
        },
        "e6139fc3bba94c58b4f8daeda560c0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f0b8de8a535468aa3036dcc739d60e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:05&lt;00:00, 33543960.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0500629cc9a746d9bed1b477d41e6f60"
          }
        },
        "f65e2a5f261940838cf1bb34926b0948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "761c699d8a614d0babd708f57b227dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f0b8de8a535468aa3036dcc739d60e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0500629cc9a746d9bed1b477d41e6f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluigilopardo/Open-World-Recognition/blob/main/ablation_study/bic_method/Open_world_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjBxkRrfQzn8",
        "outputId": "a9b3441b-1a5c-4683-83cc-eec27f245e13"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4LwmKwRot-",
        "outputId": "68330933-c95f-4472-d8eb-4e57825889db"
      },
      "source": [
        "if not os.path.isdir('./owr'):\n",
        "  !git clone https://github.com/gianluigilopardo/Open-World-Recognition.git\n",
        "  !mv 'Open-World-Recognition' 'owr'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Open-World-Recognition'...\n",
            "remote: Enumerating objects: 552, done.\u001b[K\n",
            "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 552 (delta 179), reused 139 (delta 103), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (552/552), 2.10 MiB | 5.70 MiB/s, done.\n",
            "Resolving deltas: 100% (330/330), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626,
          "referenced_widgets": [
            "253cb41ffedc4cc0a2440b87972ab607",
            "e567fb7101e349c6ac09f0e931e071cd",
            "f8b8bef9195e44bc87d18d44f3b59d6b",
            "e6139fc3bba94c58b4f8daeda560c0f3",
            "f65e2a5f261940838cf1bb34926b0948",
            "761c699d8a614d0babd708f57b227dcb",
            "5f0b8de8a535468aa3036dcc739d60e8",
            "0500629cc9a746d9bed1b477d41e6f60"
          ]
        },
        "id": "FxMSpIJeR046",
        "outputId": "0e273d5f-89b1-45c5-99ec-5171ea79859d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sn\n",
        "import torch.nn as nn\n",
        "\n",
        "# our modules\n",
        "from owr.ablation_study.bic_method import BiC\n",
        "from owr.ablation_study.bic_method.dataset import *\n",
        "\n",
        "###### This script is the main for running BiC Method on CIFAR 100 dataset\n",
        "# remeber to set lr = 0.1 in params before running BiC.\n",
        "print(\"BiC Method running on CIFAR 100\")\n",
        "print(f\"learning rate : {params.LR}\")\n",
        "print(f\"learning rate schedule epochs: {params.STEP_SIZE}\")\n",
        "\n",
        "############################################################\n",
        "#################### DATA MANAGEMENT #######################\n",
        "\n",
        "cifar = datasets.cifar.CIFAR100\n",
        "# transformers\n",
        "train_transformer = transforms.Compose([transforms.RandomCrop(size=32, padding=4),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                        ])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                       ])\n",
        "train_dataset = cifar('data', train=True, download=True, transform=train_transformer)\n",
        "test_dataset = cifar('data', train=False, download=True, transform=test_transformer)\n",
        "# get the incremental subdivision of classes - Inside the function there is a seed that can be changed\n",
        "# in order to evaluate another class sequence\n",
        "splits = utils.splitter()\n",
        "###########################################################################\n",
        "##################### instantiate BiC object###############################\n",
        "\n",
        "model = BiC.BiC_method(num_classes=params.NUM_CLASSES).to(params.DEVICE)\n",
        "# How many parameters to fit?\n",
        "# print(len([par for par in model.parameters()])) # 101 tensors as parameters without bias corrcetion\n",
        "# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# print(\"Solver total trainable parameters : \", total_params) # Solver total trainable parameters :  472756 (before Bias correction)\n",
        "\n",
        "############################################################################\n",
        "# lists for the evaluation phase\n",
        "\n",
        "test_indexes = []  # this list will store the test indexes for all seen classes\n",
        "# vectors for accuracy curves\n",
        "new_test_accs = []\n",
        "test_accs = []\n",
        "\n",
        "#############################################################################\n",
        "##################  RUN THE INCREMENTAL TRAINING ############################\n",
        "\n",
        "for task in range(0, params.NUM_CLASSES, params.TASK_SIZE):\n",
        "\n",
        "    #########################################################################\n",
        "    ######## MANAGE THE DATA FOR THE CURRENT TASK ###########################\n",
        "\n",
        "    # extract the correct indexes for the current task\n",
        "    ###### INDEXES ######\n",
        "    all_train_indexes, corrisponding_labels = utils.get_task_indexes_with_labels(train_dataset, task)\n",
        "    test_indexes = test_indexes + utils.get_task_indexes(test_dataset, task)\n",
        "    new_test_indexes = utils.get_task_indexes(test_dataset, task)\n",
        "\n",
        "    ##### SUBSET #####\n",
        "    all_train_subset = Subset(train_dataset, all_train_indexes, transform=train_transformer)\n",
        "    test_subset = Subset(test_dataset, test_indexes, transform=test_transformer)\n",
        "    new_test_subset = Subset(test_dataset, new_test_indexes, transform=test_transformer)\n",
        "\n",
        "    #### LOADERS #####\n",
        "    all_train_loader = DataLoader(all_train_subset, num_workers=params.NUM_WORKERS,\n",
        "                                  batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_subset, num_workers=params.NUM_WORKERS,\n",
        "                             batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    new_test_loader = DataLoader(new_test_subset, num_workers=params.NUM_WORKERS,\n",
        "                                 batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    ################################### Incremental Training ##########################################\n",
        "    # in every task the model will see new classes: become able to classify them and stores a few for the following steps\n",
        "    final_loss_curve, final_training_accs, _ = model.incremental_training(train_dataset, train_transformer, task,\n",
        "                                                                          new_test_loader, test_loader)\n",
        "    print(f\"loss_curve = {final_loss_curve}\")\n",
        "    print(f\"accuracy_curve = {final_training_accs}\")\n",
        "\n",
        "    # if you want plot it (it slow the training)\n",
        "    # plt.plot(final_loss_curve, 'go-', label='loss curve')\n",
        "    # plt.plot(final_training_accs, 'rs-', label='training accuracies')\n",
        "    # plt.legend()\n",
        "    # plt.title(f\"Task : {task}\")\n",
        "    # plt.show()\n",
        "    ############################## EVALUATION OF THE CURRENT INCREMENTAL STEP #########################\n",
        "\n",
        "    with torch.no_grad():\n",
        "        print('\\n EVALUATION \\n')\n",
        "        ### Get all the discovered classes\n",
        "        classes = []\n",
        "        for i, x in enumerate(splits[:int(task / params.TASK_SIZE) + 1]):\n",
        "            v = np.array(x)\n",
        "            classes = np.concatenate((classes, v), axis=None)\n",
        "            classes = classes.astype(int)\n",
        "        ####  NEW TEST DATA ####\n",
        "        total = 0.0\n",
        "        running_corrects = 0.0\n",
        "        for img, lbl, _ in new_test_loader:\n",
        "            img = img.float().to(params.DEVICE)\n",
        "            outputs = model(img, task)\n",
        "            cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), classes[None, :], axis=1).to(params.DEVICE)\n",
        "            _, preds = torch.max(cut_outputs.data, 1)\n",
        "            preds = preds.to(params.DEVICE)\n",
        "            labels = utils.map_splits(lbl, classes).to(params.DEVICE)\n",
        "            total += len(lbl)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        accuracy = running_corrects / float(total)\n",
        "        new_test_accs.append(accuracy)\n",
        "        print(f'task: {task}', f'test accuracy on only new classes = {accuracy}')\n",
        "\n",
        "        ##### OLD & NEW TEST DATA ####\n",
        "        total = 0.0\n",
        "        running_corrects = 0.0\n",
        "        tot_preds = []\n",
        "        tot_lab = []\n",
        "        for img, lbl, _ in test_loader:\n",
        "            img = img.float().to(params.DEVICE)\n",
        "            outputs = model(img, task)\n",
        "            cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), classes[None, :], axis=1).to(params.DEVICE)\n",
        "            _, preds = torch.max(cut_outputs.data, 1)\n",
        "            preds = preds.to(params.DEVICE)\n",
        "            labels = utils.map_splits(lbl, classes).to(params.DEVICE)\n",
        "\n",
        "            tot_preds = np.concatenate((tot_preds, preds.data.cpu().numpy()))\n",
        "            tot_lab = np.concatenate((tot_lab, labels.data.cpu().numpy()))\n",
        "\n",
        "            total += len(lbl)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        accuracy = running_corrects / float(total)\n",
        "        test_accs.append(accuracy)\n",
        "        print(f'task: {task}', f'test accuracy on old and new classes = {accuracy}')\n",
        "\n",
        "######################################################################################\n",
        "#################### PLOT THE WHOLE ACCURACY CURVES ##################################\n",
        "\n",
        "print(f\"New test accuracies : {new_test_accs}\")\n",
        "print(f\"Test accuracies : {test_accs}\")\n",
        "plt.plot(new_test_accs, 'go-', label='new testing accuracies', linewidth=2)\n",
        "plt.plot(test_accs, 'rs-', label='testing accuracies')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiC Method running on CIFAR 100\n",
            "learning rate : 0.1\n",
            "learning rate schedule epochs: [49, 63]\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "253cb41ffedc4cc0a2440b87972ab607",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "\n",
            "FIRST STAGE OF TRAINING, Task : 0\n",
            "\n",
            "Step: 0, Epoch: 0, Loss: 2.3254323303699493, Accuracy: 0.226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea5a236dc3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# in every task the model will see new classes: become able to classify them and stores a few for the following steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     final_loss_curve, final_training_accs, _ = model.incremental_training(train_dataset, train_transformer, task,\n\u001b[0;32m---> 90\u001b[0;31m                                                                           new_test_loader, test_loader)\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss_curve = {final_loss_curve}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"accuracy_curve = {final_training_accs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/owr/ablation_study/bic_method/BiC.py\u001b[0m in \u001b[0;36mincremental_training\u001b[0;34m(self, train_dataset, train_transformer, task, new_test_loader, test_loader, with_rejection)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nFIRST STAGE OF TRAINING, Task : {task}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# first stage training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mloss_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_stage_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# before performing the bias correction we evaluate the baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/owr/ablation_study/bic_method/BiC.py\u001b[0m in \u001b[0;36mfirst_stage_training\u001b[0;34m(self, data_loader, classes, task, train_splits)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# .long()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mmapped_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# features=False : use fully connected layer (see ResNet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/owr/ablation_study/bic_method/utils.py\u001b[0m in \u001b[0;36mmap_splits\u001b[0;34m(labels, splits)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0msplits_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmapped_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFn3bM0R8Cn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}