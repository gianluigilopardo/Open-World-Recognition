{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "iCaRLMain_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py38_pytorch",
      "language": "python",
      "name": "conda-env-py38_pytorch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b3b8654144440aa824eee32c4672903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d105feb0d1194e8199c094870e7a0f17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_509cd455018a4a1eb08a57bf4298885f",
              "IPY_MODEL_9353197a2e0a4410b77537b8060e3cf2"
            ]
          }
        },
        "d105feb0d1194e8199c094870e7a0f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "509cd455018a4a1eb08a57bf4298885f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca38fe73db8948b2a0600405b9acc104",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03d0ea9c891f4e62aced746316953e13"
          }
        },
        "9353197a2e0a4410b77537b8060e3cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c14b53d7f92947949d6c593dd5055c48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:09&lt;00:00, 17832916.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02798c436e4d499fbfce559e742bed9c"
          }
        },
        "ca38fe73db8948b2a0600405b9acc104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03d0ea9c891f4e62aced746316953e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c14b53d7f92947949d6c593dd5055c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02798c436e4d499fbfce559e742bed9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluigilopardo/Open-World-Recognition/blob/main/our_modifications/incremental_learning/ICARL/knn/iCaRLMain_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmAxWzsbzUEG"
      },
      "source": [
        "RUN KNN WITH BCE BCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3hcjgTPy1Xa",
        "outputId": "8361b882-e1d5-4551-d105-a960be5aa918"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6495a01-d6c0-4967-c198-e0b7ccdb00f2"
      },
      "source": [
        "if not os.path.isdir('./owr'):\n",
        "  !git clone https://github.com/gianluigilopardo/Open-World-Recognition.git\n",
        "  !mv 'Open-World-Recognition' 'owr'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Open-World-Recognition'...\n",
            "remote: Enumerating objects: 480, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 480 (delta 141), reused 146 (delta 107), pack-reused 257\u001b[K\n",
            "Receiving objects: 100% (480/480), 2.07 MiB | 10.78 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbc5JEp-MIc2"
      },
      "source": [
        "from owr.our_modifications.incremental_learning.ICARL.knn import ResNet\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.dataset import Subset\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import classify\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import incremental_train\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import update_representation\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import construct_exemplar_set\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import reduce_exemplars\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.icarl import generate_new_exemplars\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.models import compute_loss\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.models import train_network\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn import params\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn import utils\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import get_classes_names\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import get_task_indexes\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import splitter\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import map_splits\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import get_classes\n",
        "from owr.our_modifications.incremental_learning.ICARL.knn.utils import get_indexes\n",
        "import owr.our_modifications.incremental_learning.ICARL.knn.models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG5dRGuxOMtB"
      },
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W41g_ZMjy1Xd",
        "outputId": "443ebfd7-6291-46ed-89a9-9dd4005fb71b"
      },
      "source": [
        "pip install seaborn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2rkcBbIKfUQ",
        "outputId": "2dc46544-5c0e-492a-dab2-f9afd5a4132f"
      },
      "source": [
        "print(params.SEED)\n",
        "print(params.NUM_WORKERS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz"
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "6b3b8654144440aa824eee32c4672903",
            "d105feb0d1194e8199c094870e7a0f17",
            "509cd455018a4a1eb08a57bf4298885f",
            "9353197a2e0a4410b77537b8060e3cf2",
            "ca38fe73db8948b2a0600405b9acc104",
            "03d0ea9c891f4e62aced746316953e13",
            "c14b53d7f92947949d6c593dd5055c48",
            "02798c436e4d499fbfce559e742bed9c"
          ]
        },
        "id": "1CSNk0NlrvAL",
        "outputId": "da413916-9063-42bb-91a4-4410c76d15fd"
      },
      "source": [
        "from torchvision import datasets\n",
        "trainDS = datasets.cifar.CIFAR100( 'data', train=True, download=True, transform=train_transformer)\n",
        "testDS = datasets.cifar.CIFAR100( 'data', train=False, download=True, transform=test_transformer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b3b8654144440aa824eee32c4672903",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL"
      },
      "source": [
        "splits = splitter()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK"
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN"
      },
      "source": [
        "exemplars = [None]*params.NUM_CLASSES\n",
        "\n",
        "test_indexes =  []\n",
        "accs_train = []\n",
        "accs_test = []\n",
        "classifier = 'nme'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W56xyFKQy1Xg"
      },
      "source": [
        "classifier = KNeighborsClassifier()\n",
        "clf_params = {'n_neighbors' : np.arange(1,19,2)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOMJWX8RM_5I"
      },
      "source": [
        "def tmp_classify(images, exemplars, model, task, train_dataset, mean=None, classifier='nme', clf_params=None):\n",
        "    if classifier == 'nme':\n",
        "        preds, mean = classify_nme(images, exemplars, model, task, train_dataset, mean)\n",
        "        return preds, mean\n",
        "    else:\n",
        "        preds, mean = classify_models(images, exemplars, model, task, train_dataset, mean, classifier, clf_params)\n",
        "        return preds, mean\n",
        "\n",
        "def classify_models(images, exemplars, model, task, train_dataset, cv, classifier, clf_params):\n",
        "    splits = utils.splitter()\n",
        "    model.train(False)\n",
        "    m = torch.nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        images = images.float().to(params.DEVICE)\n",
        "        x_test = model(images)\n",
        "        x_test = m(x_test)\n",
        "    if cv == None:\n",
        "        analyzed_classes = []\n",
        "        for i in range(int(task / params.TASK_SIZE)+1):\n",
        "            analyzed_classes = np.concatenate((analyzed_classes, splits[i]))\n",
        "        l = []\n",
        "        for k in range(len(analyzed_classes)):\n",
        "            class_k = int(analyzed_classes[k])\n",
        "            l.extend(exemplars[class_k])\n",
        "\n",
        "        transformer = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        subset = Subset(train_dataset, l, transformer)\n",
        "        data_loader = DataLoader(subset, num_workers=params.NUM_WORKERS, batch_size=params.BATCH_SIZE)\n",
        "        df = pd.DataFrame(columns = ['data', 'labels'])\n",
        "        for images, labels, idxs in data_loader:\n",
        "            with torch.no_grad():\n",
        "                images = images.float().to(params.DEVICE)\n",
        "                x = model(images)\n",
        "                x = m(x)\n",
        "                tmp = pd.DataFrame()\n",
        "                tmp['data'] = x.to('cpu')\n",
        "                tmp['labels'] = labels.to('cpu')\n",
        "                df = df.append(tmp)\n",
        "        cv = GridSearchCV(classifier, clf_params)\n",
        "        cv.fit(list(df['data']),list(df['labels']) )\n",
        "        print(cv.best_params_)\n",
        "    preds = cv.predict(x_test.to('cpu'))\n",
        "    return torch.tensor(preds), cv"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcFjbBGrOMz6",
        "outputId": "07890168-f08f-47a4-ebae-d70b6cc91342"
      },
      "source": [
        "for task in range(0, params.NUM_TASKS*params.TASK_SIZE, params.TASK_SIZE):\n",
        "    train_indexes = get_task_indexes(trainDS, task)\n",
        "    test_indexes = test_indexes + get_task_indexes(testDS, task)\n",
        "\n",
        "    train_dataset = Subset(trainDS, train_indexes, transform = train_transformer)\n",
        "    test_dataset = Subset(testDS, test_indexes, transform = test_transformer)\n",
        "\n",
        "    train_loader = DataLoader( train_dataset, num_workers=2, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader( test_dataset, num_workers=2, batch_size=params.BATCH_SIZE , shuffle=True )\n",
        "    print(task)\n",
        "    ICaRL, exemplars = incremental_train(trainDS, ICaRL, exemplars, task, train_transformer, loss_version='opt1')\n",
        "    col = []\n",
        "    for i,x in enumerate( splits[ :int(task/10) + 1]) : \n",
        "        v = np.array(x)\n",
        "        col = np.concatenate( (col,v), axis = None)\n",
        "        col = col.astype(int)\n",
        "    mean = None\n",
        "    total = 0.0\n",
        "    running_corrects = 0.0\n",
        "    \n",
        "    for img, lbl, _ in train_loader:\n",
        "        img = img.float().to(params.DEVICE)\n",
        "        preds, mean = tmp_classify(img, exemplars, ICaRL, task, trainDS, mean, classifier, clf_params)\n",
        "        preds = preds.to(params.DEVICE)\n",
        "        if classifier == 'nme':\n",
        "            labels = map_splits(lbl, col).to(params.DEVICE)\n",
        "        else:\n",
        "            labels = lbl.to(params.DEVICE)\n",
        "        total += len(lbl)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    accuracy = float(running_corrects/total)\n",
        "    print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "    accs_train.append(accuracy)\n",
        "\n",
        "    total = 0.0\n",
        "    running_corrects = 0.0\n",
        "    tot_preds = []\n",
        "    tot_lab = []\n",
        "    for img, lbl, _ in test_loader:\n",
        "        img = img.float().to(params.DEVICE)\n",
        "        preds, _ = tmp_classify(img, exemplars, ICaRL, task, trainDS, mean, classifier, clf_params)\n",
        "        preds = preds.to(params.DEVICE)\n",
        "        if classifier == 'nme':\n",
        "            labels = map_splits(lbl, col).to(params.DEVICE)\n",
        "        else:\n",
        "            labels = lbl.to(params.DEVICE)\n",
        "        tot_preds = np.concatenate( ( tot_preds, preds.data.cpu().numpy() ) )\n",
        "        tot_lab = np.concatenate( (tot_lab, labels.data.cpu().numpy()  ) )\n",
        "        total += len(lbl)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    accuracy = float(running_corrects/total)\n",
        "    print(f'task: {task}', f'test accuracy = {accuracy}')\n",
        "    accs_test.append(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Step: 0, Epoch: 0, Loss: 0.020933039486408234, Accuracy: 0.2102\n",
            "Step: 0, Epoch: 1, Loss: 0.02003304660320282, Accuracy: 0.4148\n",
            "Step: 0, Epoch: 2, Loss: 0.021279089152812958, Accuracy: 0.4764\n",
            "Step: 0, Epoch: 3, Loss: 0.02608495019376278, Accuracy: 0.5402\n",
            "Step: 0, Epoch: 4, Loss: 0.01541602611541748, Accuracy: 0.575\n",
            "Step: 0, Epoch: 5, Loss: 0.033868249505758286, Accuracy: 0.6004\n",
            "Step: 0, Epoch: 6, Loss: 0.02914546988904476, Accuracy: 0.6314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNzFNzSPGNGx"
      },
      "source": [
        "torch.save(ICaRL, \"./knnModel.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuKdfB7eZXo"
      },
      "source": [
        "n = 1254\n",
        "images_test = [n]\n",
        "example_test_ds = Subset(testDS, images_test, transform = test_transformer)\n",
        "example_test_loader = DataLoader( example_test_ds, num_workers=2, batch_size=params.BATCH_SIZE , shuffle=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKj7SsndPcjl"
      },
      "source": [
        "x = testDS.__getitem__(n)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu4me0k4OVlt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "show(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIn4lMgOLFJM"
      },
      "source": [
        "m = torch.nn.Softmax(dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2Lw43Dej3z"
      },
      "source": [
        "for img, lbl, _ in example_test_loader:\n",
        "    img = img.float().to(params.DEVICE)\n",
        "    classify_preds, _ = tmp_classify(img, exemplars, ICaRL, task, trainDS, mean, classifier, clf_params)\n",
        "    outputs_preds = m(ICaRL(img, features = 0).to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apAJr3KGLa2J"
      },
      "source": [
        "print(lbl, testDS.classes[lbl])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yafnazHXMht_"
      },
      "source": [
        "df = pd.DataFrame(columns=['class_name', 'value'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip4dvxmqLCay"
      },
      "source": [
        "for i, el in enumerate(outputs_preds.tolist()[0]):\n",
        "  df.loc[i] = [testDS.classes[i], el]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjPtNRbmNEdH"
      },
      "source": [
        "df.sort_values(by=['value'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nxb2dDXLVJD"
      },
      "source": [
        "np.argmax(outputs_preds.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXF1hPUILcul"
      },
      "source": [
        "classify_preds"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}