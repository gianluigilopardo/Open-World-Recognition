{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Open_world_main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgSPCmT8E0oaQr8Ak2MGWa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00624eecaf2c40b79fd6edb237e6274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56f2c85914484956a9646d22f6155a4f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a743ecbadfbb42cc92e35b0bf6a009ca",
              "IPY_MODEL_7d37293e9c1e4cd296fc6cccaf98b30d"
            ]
          }
        },
        "56f2c85914484956a9646d22f6155a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a743ecbadfbb42cc92e35b0bf6a009ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7173a93238e46118e4755765bf2e079",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cff083b117c4bbcb4e9d161205cb7e6"
          }
        },
        "7d37293e9c1e4cd296fc6cccaf98b30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37e15471615e422a97d30a8282549875",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:19&lt;00:00, 8561796.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be04d698b1f54c12919d6fb85f70e677"
          }
        },
        "a7173a93238e46118e4755765bf2e079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cff083b117c4bbcb4e9d161205cb7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37e15471615e422a97d30a8282549875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be04d698b1f54c12919d6fb85f70e677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluigilopardo/Open-World-Recognition/blob/main/open_world/Open_world_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjBxkRrfQzn8",
        "outputId": "25adc08d-855b-48eb-a441-4f324f94044f"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4LwmKwRot-",
        "outputId": "e1ac2f84-e565-4282-d05b-35fa4bca1cbe"
      },
      "source": [
        "if not os.path.isdir('./owr'):\n",
        "  !git clone https://github.com/gianluigilopardo/Open-World-Recognition.git\n",
        "  !mv 'Open-World-Recognition' 'owr'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Open-World-Recognition'...\n",
            "remote: Enumerating objects: 487, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 487 (delta 135), reused 143 (delta 103), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (487/487), 2.08 MiB | 5.67 MiB/s, done.\n",
            "Resolving deltas: 100% (286/286), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683,
          "referenced_widgets": [
            "00624eecaf2c40b79fd6edb237e6274a",
            "56f2c85914484956a9646d22f6155a4f",
            "a743ecbadfbb42cc92e35b0bf6a009ca",
            "7d37293e9c1e4cd296fc6cccaf98b30d",
            "a7173a93238e46118e4755765bf2e079",
            "2cff083b117c4bbcb4e9d161205cb7e6",
            "37e15471615e422a97d30a8282549875",
            "be04d698b1f54c12919d6fb85f70e677"
          ]
        },
        "id": "FxMSpIJeR046",
        "outputId": "ff3fe2a5-d544-48b0-d9a2-20e44532c298"
      },
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sn\n",
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "\n",
        "from owr.open_world import BiC\n",
        "from owr.open_world import ResNet\n",
        "from owr.open_world import models\n",
        "from owr.open_world import params\n",
        "from owr.open_world import utils\n",
        "from owr.open_world.dataset import *\n",
        "from owr.open_world import icarl\n",
        "from collections import defaultdict\n",
        "\n",
        "# This script is the main for running the fixed-threshold rejection strategy both for\n",
        "# iCaRL and BiC models.\n",
        "# remeber to set lr = 0.1 in params before running BiC.\n",
        "\n",
        "### Useful functions for compute evaluation metrics ###\n",
        "def return0dot0():\n",
        "    return 0.0\n",
        "def returnList():\n",
        "    return []\n",
        "def harmonic_mean(a,b):\n",
        "    return (2 * a * b) / (a + b)\n",
        "\n",
        "soft_max = nn.Softmax(dim=1)\n",
        "\n",
        "print(\"iCaRL/BiC open world recognition\")\n",
        "print(f\"learning rate : {params.LR}\")\n",
        "print(f\"learning rate schedule epochs: {params.STEP_SIZE}\")\n",
        "\n",
        "############################################################\n",
        "#################### DATA MANAGEMENT #######################\n",
        "\n",
        "cifar = datasets.cifar.CIFAR100\n",
        "# transformers\n",
        "train_transformer = transforms.Compose([transforms.RandomCrop(size=32, padding=4),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                        ])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                       ])\n",
        "train_dataset = cifar('data', train=True, download=True, transform=train_transformer)\n",
        "test_dataset = cifar('data', train=False, download=True, transform=test_transformer)\n",
        "# get the incremental subdivision of classes - Inside the function there is a seed that can be changed\n",
        "# in order to evaluate another class sequence\n",
        "# splits\n",
        "splits = utils.splitter()\n",
        "print('splits: ' + str(splits))\n",
        "\n",
        "# Get the open_world_test_indexes, i.e. test set for evaluate the capability of reject\n",
        "# (last 50 classes of the current random splits)\n",
        "open_world_test_indexes = [] # list of indexes\n",
        "for task in range(params.NUM_CLASSES//2,params.NUM_CLASSES, params.TASK_SIZE):\n",
        "    open_world_test_indexes = open_world_test_indexes + utils.get_task_indexes(test_dataset, task)\n",
        "open_world_test_subset = Subset(test_dataset, open_world_test_indexes, transform=test_transformer)\n",
        "open_word_test_loader = DataLoader(open_world_test_subset, num_workers=params.NUM_WORKERS,\n",
        "                                     batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "# this test set contains only unknown classes for our purpose\n",
        "closed_word_test_indexes = [] # test set for closed world with and without rejection\n",
        "\n",
        "###################################################################################\n",
        "##################### instantiate the model's object ##############################\n",
        "\n",
        "# choose the model\n",
        "# The followiing two for iCaRL\n",
        "# model = ResNet.resnet32(num_classes=params.NUM_CLASSES).to(params.DEVICE)\n",
        "# exemplars = [None] * params.NUM_CLASSES\n",
        "\n",
        "# The following for BiC\n",
        "model = BiC.BiC_method(num_classes=params.NUM_CLASSES).to(params.DEVICE)\n",
        "\n",
        "############################################################################\n",
        "##### lists for the evaluation phase\n",
        "# They will store the accuracy curves\n",
        "closed_word_without_rejection_accuracy = []\n",
        "closed_word_with_rejection_accuracy = defaultdict(returnList)\n",
        "open_set_accuracy = defaultdict(returnList)\n",
        "open_world_aritmetic_mean = {} # defaultdict(returnList)\n",
        "open_world_harmonic_mean = {} # defaultdict(returnList)\n",
        "\n",
        "###################################################################################\n",
        "##################### set a list of rejection threesholds #########################\n",
        "\n",
        "rejection_global_treesholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "# Set the value for the unknown label\n",
        "unknown_label = -1\n",
        "\n",
        "for task in range(0, params.NUM_CLASSES // 2, params.TASK_SIZE):\n",
        "    not_known = 0 # for compute a statistics\n",
        "    ################################################################################################\n",
        "    ############################ Data employed in this task ########################################\n",
        "    # Train and Test datasets for this tasks\n",
        "    train_indexes = utils.get_task_indexes(train_dataset, task)\n",
        "    closed_word_test_indexes = closed_word_test_indexes + utils.get_task_indexes(test_dataset, task)\n",
        "    new_test_indexes = utils.get_task_indexes(test_dataset, task)\n",
        "\n",
        "    train_subset = Subset(train_dataset, train_indexes, transform=train_transformer)\n",
        "    test_subset = Subset(test_dataset, closed_word_test_indexes, transform=test_transformer)\n",
        "    new_test_subset = Subset(test_dataset, new_test_indexes, transform=test_transformer)\n",
        "\n",
        "    train_loader = DataLoader(train_subset, num_workers=params.NUM_WORKERS,\n",
        "                              batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    closed_word_test_loader = DataLoader(test_subset, num_workers=params.NUM_WORKERS,\n",
        "                             batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    new_test_loader = DataLoader(new_test_subset, num_workers=params.NUM_WORKERS,\n",
        "                             batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    ################################### Incremental Training ##########################################\n",
        "    # for iCaRL\n",
        "    # model, exemplars = icarl.incremental_train(train_dataset, model, exemplars, task, train_transformer)\n",
        "    # for BiC\n",
        "    _, _, _ = model.incremental_training(train_dataset, train_transformer, task, new_test_loader, closed_word_test_loader)\n",
        "\n",
        "    ################################### Evaluation ####################################################\n",
        "    # currently discovered classes\n",
        "    classes = []\n",
        "    for i, x in enumerate(splits[:int(task / params.TASK_SIZE) + 1]):\n",
        "        v = np.array(x)\n",
        "        classes = np.concatenate((classes, v), axis=None)\n",
        "        classes = classes.astype(int)\n",
        "    with torch.no_grad():\n",
        "        ############## Closed word without rejection\n",
        "        total = 0.0\n",
        "        running_corrects = 0.0\n",
        "        not_known = 0\n",
        "        batch = 1\n",
        "\n",
        "        for img, lbl, _ in closed_word_test_loader:\n",
        "            img = img.float().to(params.DEVICE)\n",
        "            # compute the models outputs\n",
        "            # for iCaRL\n",
        "            # outputs = model(img).to(params.DEVICE)\n",
        "            # for BiC\n",
        "            outputs = model(img, task).to(params.DEVICE)\n",
        "            cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), classes[None, :], axis=1).to(params.DEVICE)\n",
        "            probs = soft_max(cut_outputs)\n",
        "\n",
        "            _, preds = torch.max(probs.data, 1)\n",
        "\n",
        "            labels = utils.map_splits(lbl, classes).to(params.DEVICE)\n",
        "            total += len(lbl)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "            batch = batch + 1\n",
        "\n",
        "        accuracy = float(running_corrects / total)\n",
        "        closed_word_without_rejection_accuracy.append(accuracy)\n",
        "        print(f'task: {task}', f'closed_word_without_rejection_accuracy = {accuracy}')\n",
        "\n",
        "        ############## Closed word with rejection\n",
        "        total = 0.0\n",
        "        running_corrects = 0.0\n",
        "        not_known = 0\n",
        "        batch = 1\n",
        "        running_corrects_dict = defaultdict(return0dot0)\n",
        "\n",
        "        for img, lbl, _ in closed_word_test_loader:\n",
        "            img = img.float().to(params.DEVICE)\n",
        "\n",
        "            # for iCaRL\n",
        "            # outputs = model(img).to(params.DEVICE)\n",
        "            # for BiC\n",
        "            outputs = model(img, task).to(params.DEVICE)\n",
        "            cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), classes[None, :], axis=1).to(params.DEVICE)\n",
        "            probs = soft_max(cut_outputs)\n",
        "\n",
        "            maxPred, preds = torch.max(probs.data, 1)\n",
        "            labels = utils.map_splits(lbl, classes).to(params.DEVICE)\n",
        "            total += len(lbl)\n",
        "            ####################################################################################################\n",
        "            ##################### APPLY THE REJECTION STRATEGY FOR EACH THRESHOLDS #############################\n",
        "            # scan 'maxPred', if the maximum probability is below the threshold predict as unknown otherwise with\n",
        "            # the corresponding 'preds' label.\n",
        "            for threeshold in rejection_global_treesholds:\n",
        "                preds_tmp = copy.deepcopy(preds)\n",
        "                # Apply the threeshold in a naive way, this can be upgraded\n",
        "                for i, p in enumerate(maxPred):\n",
        "                    if p <= threeshold:\n",
        "                        preds_tmp[i] = unknown_label\n",
        "                        not_known = not_known + 1\n",
        "                running_corrects_dict[str(threeshold)] += torch.sum(preds_tmp == labels.data).data.item()\n",
        "            batch = batch + 1\n",
        "        for threeshold in rejection_global_treesholds:\n",
        "            accuracy = float(running_corrects_dict[str(threeshold)] / total)\n",
        "            closed_word_with_rejection_accuracy[str(threeshold)].append(accuracy)\n",
        "            print(f'task: {task}' f'threeshold : {threeshold}, closed_word_with_rejection_accuracy = {accuracy}')\n",
        "\n",
        "        ############################### Open Word Scenario\n",
        "        total = 0.0\n",
        "        running_corrects = 0.0\n",
        "        not_known = 0\n",
        "        batch = 1\n",
        "        running_corrects_dict = defaultdict(return0dot0)\n",
        "\n",
        "        for img, _ , _ in open_word_test_loader:\n",
        "            # we do not need labels, this are only unknown\n",
        "            img = img.float().to(params.DEVICE)\n",
        "\n",
        "            # for iCaRL\n",
        "            # outputs = model(img).to(params.DEVICE)\n",
        "            # for BiC\n",
        "            outputs = model(img, task).to(params.DEVICE)\n",
        "            cut_outputs = np.take_along_axis(outputs.to(params.DEVICE), classes[None, :], axis=1).to(params.DEVICE)\n",
        "            probs = soft_max(cut_outputs)\n",
        "\n",
        "            maxPred, preds = torch.max(probs.data, 1)\n",
        "            total += len(preds)\n",
        "            ####################################################################################################\n",
        "            ##################### APPLY THE REJECTION STRATEGY FOR EACH THRESHOLDS #############################\n",
        "            # scan 'maxPred', if the maximum probability is below the threshold predict as unknown otherwise with\n",
        "            # the corresponding 'preds' label.\n",
        "            for threeshold in rejection_global_treesholds:\n",
        "                preds_tmp = copy.deepcopy(preds)\n",
        "                # Apply the threeshold in a naive way, this can be upgraded\n",
        "                for i, p in enumerate(maxPred):\n",
        "                    if p <= threeshold:\n",
        "                        preds_tmp[i] = unknown_label\n",
        "                        not_known = not_known + 1\n",
        "                running_corrects_dict[str(threeshold)] += torch.sum(preds_tmp == unknown_label).data.item()\n",
        "            batch = batch + 1\n",
        "        for threeshold in rejection_global_treesholds:\n",
        "            accuracy = float(running_corrects_dict[str(threeshold)] / total)\n",
        "            open_set_accuracy[str(threeshold)].append(accuracy)\n",
        "            print(f'task: {task}' f'threeshold : {threeshold}, open_set_accuracy = {accuracy}')\n",
        "\n",
        "#### THE INCREMENTAL TRAINING HAS ENDED ####\n",
        "############## Compute the Open World Harmonic and Aritmetic Mean\n",
        "for threeshold in rejection_global_treesholds:\n",
        "    open_world_aritmetic_mean[str(threeshold)] = [(a + b)/2 for a,b in zip(closed_word_with_rejection_accuracy[str(threeshold)], open_set_accuracy[str(threeshold)])]\n",
        "    open_world_harmonic_mean[str(threeshold)] = [harmonic_mean(a,b) for a,b in zip(closed_word_with_rejection_accuracy[str(threeshold)], open_set_accuracy[str(threeshold)])]\n",
        "\n",
        "##########################################################################################\n",
        "############################ PRINT FINAL RESULTS #########################################\n",
        "print(\"\\n RESULTS : \")\n",
        "\n",
        "print(\"\\n Closed world without rejection accuracy\")\n",
        "print(closed_word_without_rejection_accuracy)\n",
        "\n",
        "print(\"\\n Closed world with rejection accuracy\")\n",
        "print(closed_word_with_rejection_accuracy)\n",
        "\n",
        "print(\"\\n Open world accuracy\")\n",
        "print(open_set_accuracy)\n",
        "\n",
        "print(\"\\n Open world aritmetic mean\")\n",
        "print(open_world_aritmetic_mean)\n",
        "\n",
        "print(\"\\n Open world harmonic mean\")\n",
        "print(open_world_harmonic_mean)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iCaRL/BiC open world recognition\n",
            "learning rate : 0.1\n",
            "learning rate schedule epochs: [49, 63]\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00624eecaf2c40b79fd6edb237e6274a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "splits: [[81, 14, 3, 94, 35, 31, 28, 17, 13, 86], [90, 18, 4, 42, 38, 34, 21, 16, 96, 76], [22, 5, 49, 45, 41, 25, 20, 85, 15, 68], [27, 6, 57, 53, 50, 32, 26, 65, 70, 82], [72, 11, 1, 80, 39, 36, 33, 12, 95, 10], [84, 24, 2, 51, 47, 46, 29, 23, 74, 19], [43, 7, 61, 59, 58, 44, 40, 37, 77, 98], [79, 30, 0, 88, 56, 55, 89, 48, 97, 73], [54, 8, 66, 64, 91, 52, 71, 9, 69, 92], [67, 99, 83, 63, 60, 87, 62, 75, 78, 93]]\n",
            "\n",
            "FIRST STAGE OF TRAINING, Task : 0\n",
            "\n",
            "Step: 0, Epoch: 0, Loss: 2.2842077910900116, Accuracy: 0.24\n",
            "Step: 0, Epoch: 1, Loss: 1.8915123283863067, Accuracy: 0.3386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e165c174e27b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# model, exemplars = icarl.incremental_train(train_dataset, model, exemplars, task, train_transformer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# for BiC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosed_word_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m################################### Evaluation ####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/owr/open_world/BiC.py\u001b[0m in \u001b[0;36mincremental_training\u001b[0;34m(self, train_dataset, train_transformer, task, new_test_loader, test_loader, with_rejection)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nFIRST STAGE OF TRAINING, Task : {task}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# first stage training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mloss_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_stage_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# before performing the bias correction we evaluate the baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/owr/open_world/BiC.py\u001b[0m in \u001b[0;36mfirst_stage_training\u001b[0;34m(self, data_loader, classes, task, train_splits)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# compute the loss written in the paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_first_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# cut_outputs take only the first #task outputs: see simplification in main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mcut_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFn3bM0R8Cn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}