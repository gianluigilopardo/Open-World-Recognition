{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ICARL-Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py38_pytorch",
      "language": "python",
      "name": "conda-env-py38_pytorch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluigilopardo/Open-World-Recognition/blob/main/baseline/ICARL_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMLAOPyrR1K"
      },
      "source": [
        "# Import GitHub repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LqwZJLUlcYH"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHhpAA-Ya95A",
        "outputId": "59f1e8cd-ab05-4571-e7a9-1efa0c391037"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVa_FlnxrXIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ff0da5-6a2e-481e-e087-00f3213d7714"
      },
      "source": [
        "if not os.path.isdir('./owr'):\n",
        "  !git clone https://github.com/gianluigilopardo/Open-World-Recognition.git\n",
        "  !mv 'Open-World-Recognition' 'owr'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Open-World-Recognition'...\n",
            "remote: Enumerating objects: 443, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 443 (delta 118), reused 143 (delta 103), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (443/443), 2.06 MiB | 5.54 MiB/s, done.\n",
            "Resolving deltas: 100% (269/269), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQyHMXzrZ5A"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbc5JEp-MIc2"
      },
      "source": [
        "from owr.baseline import ResNet\n",
        "from owr.baseline.dataset import Subset\n",
        "from owr.baseline.icarl import classify\n",
        "from owr.baseline.icarl import incremental_train\n",
        "from owr.baseline.icarl import update_representation\n",
        "from owr.baseline.icarl import construct_exemplar_set\n",
        "from owr.baseline.icarl import reduce_exemplars\n",
        "from owr.baseline.icarl import generate_new_exemplars\n",
        "from owr.baseline.models import compute_loss\n",
        "from owr.baseline.models import train_network\n",
        "from owr.baseline import params\n",
        "from owr.baseline import utils\n",
        "from owr.baseline.utils import get_classes_names\n",
        "from owr.baseline.utils import get_task_indexes\n",
        "from owr.baseline.utils import splitter\n",
        "from owr.baseline.utils import map_splits\n",
        "from owr.baseline.utils import get_classes\n",
        "from owr.baseline.utils import get_indexes\n",
        "import owr.baseline.models"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG5dRGuxOMtB"
      },
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rkcBbIKfUQ"
      },
      "source": [
        "print(params.SEED)\n",
        "print(params.NUM_WORKERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTKyyIbea95E"
      },
      "source": [
        "print(params.NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FlAkShyryrf"
      },
      "source": [
        "# Define Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP2iR2vl3Wiz"
      },
      "source": [
        "train_transformer = transforms.Compose([transforms.RandomCrop(size = 32, padding=4),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transformer = transforms.Compose([transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSNk0NlrvAL"
      },
      "source": [
        "from torchvision import datasets\n",
        "trainDS = datasets.cifar.CIFAR100( 'data', train=True, download=True, transform=train_transformer)\n",
        "testDS = datasets.cifar.CIFAR100( 'data', train=False, download=True, transform=test_transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ge3VayryJL"
      },
      "source": [
        "splits = splitter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxTlFF_rkfe"
      },
      "source": [
        "# Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZtPkiPrmQK"
      },
      "source": [
        "ICaRL = ResNet.resnet32(num_classes=100)\n",
        "ICaRL =  ICaRL.to(params.DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI8EyFmpOikN"
      },
      "source": [
        "exemplars = [None]*params.NUM_CLASSES\n",
        "\n",
        "test_indexes =  []\n",
        "accs_train = []\n",
        "accs_test = []\n",
        "classifier = 'nme'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUJ-dzyFa95H"
      },
      "source": [
        "#classifier = KNeighborsClassifier()\n",
        "#clf_params = {'n_neighbors' : np.arange(3,13,2)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFjbBGrOMz6"
      },
      "source": [
        "for task in range(0, params.NUM_TASKS*params.TASK_SIZE, params.TASK_SIZE):\n",
        "    train_indexes = get_task_indexes(trainDS, task)\n",
        "    test_indexes = test_indexes + get_task_indexes(testDS, task)\n",
        "\n",
        "    train_dataset = Subset(trainDS, train_indexes, transform = train_transformer)\n",
        "    test_dataset = Subset(testDS, test_indexes, transform = test_transformer)\n",
        "\n",
        "    train_loader = DataLoader( train_dataset, num_workers=2, batch_size=params.BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader( test_dataset, num_workers=2, batch_size=params.BATCH_SIZE , shuffle=True )\n",
        "    print(task)\n",
        "    ICaRL, exemplars = incremental_train(trainDS, ICaRL, exemplars, task, train_transformer)\n",
        "    col = []\n",
        "    for i,x in enumerate( splits[ :int(task/10) + 1]) : \n",
        "        v = np.array(x)\n",
        "        col = np.concatenate( (col,v), axis = None)\n",
        "        col = col.astype(int)\n",
        "    mean = None\n",
        "    total = 0.0\n",
        "    running_corrects = 0.0\n",
        "    \n",
        "    for img, lbl, _ in train_loader:\n",
        "        img = img.float().to(params.DEVICE)        \n",
        "        \n",
        "        preds, mean = classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "        preds = preds.to(params.DEVICE)\n",
        "        if classifier == 'nme':\n",
        "            labels = map_splits(lbl, col).to(params.DEVICE)\n",
        "        else:\n",
        "            labels = lbl.to(params.DEVICE)\n",
        "        total += len(lbl)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        '''\n",
        "        #use the fc layer:\n",
        "        outputs = ICaRL(img)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds.to('cpu') == lbl.data).data.item()\n",
        "        total += len(lbl)\n",
        "        '''\n",
        "    accuracy = float(running_corrects/total)\n",
        "    print(f'task: {task}', f'train accuracy = {accuracy}')\n",
        "    accs_train.append(accuracy)\n",
        "\n",
        "    total = 0.0\n",
        "    running_corrects = 0.0\n",
        "    tot_preds = []\n",
        "    tot_lab = []\n",
        "    for img, lbl, _ in test_loader:\n",
        "        img = img.float().to(params.DEVICE)\n",
        "\n",
        "        preds, _ = classify(img, exemplars, ICaRL, task, trainDS, mean)\n",
        "        preds = preds.to(params.DEVICE)\n",
        "        if classifier == 'nme':\n",
        "            labels = map_splits(lbl, col).to(params.DEVICE)\n",
        "        else:\n",
        "            labels = lbl.to(params.DEVICE)\n",
        "        tot_preds = np.concatenate( ( tot_preds, preds.data.cpu().numpy() ) )\n",
        "        tot_lab = np.concatenate( (tot_lab, labels.data.cpu().numpy()  ) )\n",
        "        total += len(lbl)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        '''\n",
        "        #use the fc layer:\n",
        "        outputs = ICaRL(img)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_corrects += torch.sum(preds.to('cpu') == lbl.data).data.item()\n",
        "        total += len(lbl)\n",
        "        '''        \n",
        "    accuracy = float(running_corrects/total)\n",
        "    print(f'task: {task}', f'test accuracy = {accuracy}')\n",
        "    accs_test.append(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}